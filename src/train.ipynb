{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b9237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script for training model: Logistic Regression, train set, \n",
    "#*****************************************************\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# To build linear model for statistical analysis and prediction\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To get diferent metric scores\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    make_scorer,    \n",
    ")\n",
    "\n",
    "# let's check the VIF of the predictors\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8acdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using statsmodels\n",
    "def model_performance_classification_statsmodels(\n",
    "    model, predictors, target, threshold=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    This is for computing different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    threshold: threshold for classifying the observation as class 1\n",
    "    \"\"\"\n",
    "\n",
    "    # checking which probabilities are greater than threshold\n",
    "    pred_temp = model.predict(predictors) > threshold #if is more than threshold then print\n",
    "    # rounding off the above values to get classes\n",
    "    pred = np.round(pred_temp)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834f2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_vif(predictors):    \n",
    "    vif_series1 = pd.Series(\n",
    "        [variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])],\n",
    "        index=predictors.columns,\n",
    "    )\n",
    "    i=0\n",
    "    for num in vif_series1: \n",
    "        num='{0:.4g}'.format(num)\n",
    "        vif_series1[i]=num\n",
    "        i=i+1\n",
    "    return vif_series1[vif_series1.values<=10], vif_series1[vif_series1.values>10]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e19d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_csv(filename):\n",
    "    df = pd.read_csv(os.path.join('../data/processed/', filename))\n",
    "    df.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c88a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(filename):\n",
    "    df=read_file_csv(filename)\n",
    "    X_train=df.drop(labels=['booking_status'],axis=1)\n",
    "    y_train=df['booking_status']\n",
    "    \n",
    "    # fitting the model on training set\n",
    "    logit = sm.Logit(y_train, X_train.astype(float))\n",
    "    lg = logit.fit(method='bfgs')\n",
    "\n",
    "    #printing training performance\n",
    "    print(\"Training Performance:\")\n",
    "    model_performance_classification_statsmodels(lg, X_train, y_train)\n",
    "    \n",
    "    #checking VIF of the predictors\n",
    "    vif_less10,vif_greater10 = checking_vif(X_train)    \n",
    "\n",
    "    #Dropping first variable\n",
    "    X_train1 = X_train.drop(\"market_segment_type_Online\", axis=1)\n",
    "    \n",
    "    #Checking VIF\n",
    "    vif_less10,vif_greater10 = checking_vif(X_train1)\n",
    "\n",
    "    #fitting the model on training set and printing performance again\n",
    "    logit1 = sm.Logit(y_train, X_train1.astype(float))\n",
    "    lg1 = logit1.fit(method='bfgs')\n",
    "    print(\"Training Performance:\")\n",
    "    model_performance_classification_statsmodels(lg1, X_train1, y_train)\n",
    "\n",
    "    #Dropping second variable    \n",
    "    X_train2 = X_train1.drop(\"no_of_week_nights_log\", axis=1)\n",
    "    \n",
    "    #Checking VIF\n",
    "    vif_less10,vif_greater10 = checking_vif(X_train2)\n",
    "    \n",
    "    #fitting the model on training set and printing performance again\n",
    "    logit2 = sm.Logit(y_train, X_train2.astype(float))\n",
    "    lg2 = logit2.fit(method='bfgs')\n",
    "    print(\"Training Performance:\")\n",
    "    model_performance_classification_statsmodels(lg2, X_train2, y_train)\n",
    "    \n",
    "    #Dropping high p-values\n",
    "    cols = X_train2.columns.tolist()\n",
    "\n",
    "    # setting an initial max p-value\n",
    "    max_p_value = 1\n",
    "\n",
    "    while len(cols) > 0:\n",
    "        # defining the train set\n",
    "        X_train_aux = X_train2[cols]\n",
    "\n",
    "        # fitting the model\n",
    "        model = sm.Logit(y_train, X_train_aux).fit(disp=False, method='bfgs')\n",
    "\n",
    "        # getting the p-values and the maximum p-value\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = max(p_values)\n",
    "\n",
    "        # name of the variable with maximum p-value\n",
    "        feature_with_p_max = p_values.idxmax()\n",
    "\n",
    "        if max_p_value > 0.05:\n",
    "            cols.remove(feature_with_p_max)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    selected_features = cols\n",
    "    print(selected_features)\n",
    "          \n",
    "    #Final training of model\n",
    "    X_train3 = X_train2[selected_features]\n",
    "    logit3 = sm.Logit(y_train, X_train3.astype(float))\n",
    "    lg3 = logit3.fit(method='bfgs')\n",
    "    print(lg3.summary())\n",
    "          \n",
    "    #saving the model to use into production later\n",
    "    filename = '../models/best_model.pkl'\n",
    "    pickle.dump(lg3, open(filename, 'wb'))\n",
    "    \n",
    "    #saving the new features selected for the model      \n",
    "    pd.Series(selected_features).to_csv(\"../data/processed/selected_features.csv\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256c88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training from main function\n",
    "def main():\n",
    "    training('booking_train.csv')\n",
    "    print('The training of model was ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d50f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.411683\n",
      "         Iterations: 35\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "Training Performance:\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.412691\n",
      "         Iterations: 35\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "Training Performance:\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.414447\n",
      "         Iterations: 35\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "Training Performance:\n",
      "['const', 'no_of_weekend_nights', 'lead_time', 'no_of_previous_bookings_not_canceled', 'avg_price_per_room', 'no_of_special_requests', 'lead_time_log', 'type_of_meal_plan_Meal Plan 2', 'type_of_meal_plan_Not Selected', 'required_car_parking_space_Yes', 'room_type_reserved_Room_Type 2', 'room_type_reserved_Room_Type 4', 'arrival_year_2018', 'arrival_month_August', 'arrival_month_December', 'arrival_month_February', 'arrival_month_January', 'arrival_month_July', 'arrival_month_May', 'arrival_month_November', 'arrival_month_September', 'market_segment_type_Corporate', 'market_segment_type_Offline']\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.413739\n",
      "         Iterations: 35\n",
      "         Function evaluations: 38\n",
      "         Gradient evaluations: 38\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         booking_status   No. Observations:                23216\n",
      "Model:                          Logit   Df Residuals:                    23193\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Wed, 03 May 2023   Pseudo R-squ.:                  0.3458\n",
      "Time:                        19:10:25   Log-Likelihood:                -9605.4\n",
      "converged:                      False   LL-Null:                       -14684.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================================\n",
      "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "const                                   -3.5360      0.130    -27.221      0.000      -3.791      -3.281\n",
      "no_of_weekend_nights                     0.1409      0.021      6.763      0.000       0.100       0.182\n",
      "lead_time                                0.0141      0.000     31.820      0.000       0.013       0.015\n",
      "no_of_previous_bookings_not_canceled    -1.0145      0.349     -2.906      0.004      -1.699      -0.330\n",
      "avg_price_per_room                       0.0166      0.001     21.423      0.000       0.015       0.018\n",
      "no_of_special_requests                  -1.5724      0.032    -48.695      0.000      -1.636      -1.509\n",
      "lead_time_log                            0.1855      0.026      7.107      0.000       0.134       0.237\n",
      "type_of_meal_plan_Meal Plan 2            0.4481      0.069      6.499      0.000       0.313       0.583\n",
      "type_of_meal_plan_Not Selected           0.2041      0.056      3.626      0.000       0.094       0.314\n",
      "required_car_parking_space_Yes          -1.2760      0.137     -9.298      0.000      -1.545      -1.007\n",
      "room_type_reserved_Room_Type 2          -0.2913      0.139     -2.103      0.035      -0.563      -0.020\n",
      "room_type_reserved_Room_Type 4          -0.2368      0.053     -4.491      0.000      -0.340      -0.133\n",
      "arrival_year_2018                        0.6764      0.064     10.576      0.000       0.551       0.802\n",
      "arrival_month_August                    -0.3440      0.064     -5.344      0.000      -0.470      -0.218\n",
      "arrival_month_December                  -1.8389      0.097    -18.922      0.000      -2.029      -1.648\n",
      "arrival_month_February                   0.4718      0.089      5.323      0.000       0.298       0.645\n",
      "arrival_month_January                   -1.2639      0.172     -7.361      0.000      -1.600      -0.927\n",
      "arrival_month_July                      -0.3678      0.067     -5.514      0.000      -0.499      -0.237\n",
      "arrival_month_May                       -0.3471      0.069     -5.004      0.000      -0.483      -0.211\n",
      "arrival_month_November                   0.3551      0.072      4.933      0.000       0.214       0.496\n",
      "arrival_month_September                 -0.3278      0.063     -5.220      0.000      -0.451      -0.205\n",
      "market_segment_type_Corporate           -1.3475      0.118    -11.435      0.000      -1.578      -1.117\n",
      "market_segment_type_Offline             -2.0098      0.056    -35.842      0.000      -2.120      -1.900\n",
      "========================================================================================================\n",
      "The training of model was ended\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
